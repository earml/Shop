{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************************************************************#\n",
    "# Elisalvo Ribeiro, e-mail:elisalvo.ribeiro@gmail.com, cel: +55 11 95937-6412 | +55 79 98861-8857 #\n",
    "#*************************************************************************************************#\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf') # remove all, equal to R's rm(list=ls())\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "#from dask.diagnostic import ProgressBar\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "### =====   Import large csv file (30 million row) with Dask   ===== ### \n",
    "########################################################################\n",
    "# **    This file contains cost and revenue data from five shop     ** #\n",
    "pathCost = 'C:/GitHub/sho/costShop.csv'\n",
    "pathCostCod = 'C:/GitHub/sho/costCodShop.csv'\n",
    "pathRevenue = 'C:/GitHub/sho/revenueShop.csv'\n",
    "pathRevenueCod = 'C:/GitHub/sho/revenueCodShop.csv'\n",
    "pathShop = 'C:/GitHub/sho/shop.csv'\n",
    "start = time.time()\n",
    "cost = dd.read_csv(pathCost, decimal = ',', sep = ';', dtype = {'Eaccount':str, 'Jc':str, 'Value':float, 'date':str, 'Manager':str, 'shop':str})\n",
    "costCod = dd.read_csv(pathCostCod, decimal = ',', sep = ';', dtype = {'Eaccount':str, 'FirstO':str, 'SecondO':str, 'descr':str})\n",
    "revenue = dd.read_csv(pathRevenue, decimal = ',', sep = ';', dtype = {'YearMonth':str, 'CodGroup':object, 'CodManager': object, 'CodShop':str,\n",
    "                                                                     'CodType':object, 'TpPeople':object, 'Id':float, 'Balance':float, 'Revenue':float})\n",
    "revenue = revenue.rename(columns = {'Id':'IdService'})\n",
    "revenueCod = dd.read_csv(pathRevenueCod, decimal = ',', sep = ';', \n",
    "                         encoding = 'Latin1', header = None, names = ['IdType', 'Type', 'IdService', 'Service'], \n",
    "                         dtype = {'IdType':object, 'Type':str, 'IdService':float, 'Service':str})\n",
    "\n",
    "shop = pd.read_excel(pathShop, sheet_name = 'Sheet1')\n",
    "finish = time.time()\n",
    "finish - start\n",
    "gc.collect()\n",
    "# revenue.info(memory_usage='deep'), revenue.head(2), revenue.dtypes, type(revenue), revenue.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Join the files ** #\n",
    "start = time.time()\n",
    "shop_revenue = revenue.merge(revenueCod.reset_index(), on = 'IdService', how = 'left')\n",
    "shop_cost = cost.merge(costCod.reset_index(), on = 'Eaccount', how = 'left')\n",
    "finish - start\n",
    "del revenue, revenueCod, cost, costCod\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** First cleaning data ** #\n",
    "# Firts I exclude all data before 2018. The 'FirstO' column contains the cost category that I need to analyze the dataset, \n",
    "# then I will turn this column to head (new labels), next exclude all missing.\n",
    "dtCost = shop_cost[shop_cost['date']>'201712'].groupby(['shop', 'date', 'FirstO'])['Value'].sum().reset_index()\n",
    "dtCost = dtCost.categorize(columns = ['FirstO'])\n",
    "dtCost['shopDate'] = dtCost['shop'] +'_'+ dtCost['date'] #Create new 'id'\n",
    "dtCost = dtCost.pivot_table(index = 'shopDate', columns = 'FirstO', values = 'Value', aggfunc = 'sum')\n",
    "dtCost = dtCost.rename(columns = {c: c.replace(\" \", '') for c in dtCost.columns}) #remove blanks\n",
    "dtCost.columns = dtCost.columns.str.replace(\"/\",'')\n",
    "dtCost = dtCost.drop(['ShopOther', 'FreeShop', 'RevenueOther'], axis = 1, errors = 'ignore') #remove variable that contains many missing\n",
    "dtCost['TotalCost'] = dtCost.iloc[:, 1:18].sum(axis = 1)\n",
    "del shop_cost\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Second cleaning data ** #\n",
    "dtRev = shop_revenue\n",
    "dtRev.columns = dtRev.columns.str.replace(\" \", \"_\")\n",
    "dtRev = dtRev.groupby(['CodShop', 'YearMonth', 'Type'])['Revenue'].sum().reset_index()\n",
    "dtRev = dtRev.categorize(columns = ['Type'])\n",
    "dtRev['shopDate'] = dtRev['CodShop'] +'_'+ dtRev['date']\n",
    "dtRev = dtRev.pivot_table(index = 'shopDate', columns = 'Type', values = 'Balance')\n",
    "dtRev = dtRev.rename(columns = {c: c.replace(\" \", \"\") for c in dtRev.columns})\n",
    "dtRev = dtRev.reset_index()\n",
    "dtRev['TotalRev'] = dtRev.iloc[:, 1:7].sum(axis = 1)\n",
    "del shop_revenue\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Join dtCost and dtRev dataset ** #\n",
    "dt = dtCost.merge(dtRev.reset_index(), on = 'shopDate', how = 'left')\n",
    "print(len(dtCost.index), len(dtRev.index)) #Note: The 'dtRev' dataset should have the same amount row of the 'dtCost', \n",
    "                                           #but don't have\n",
    "del dtCost, dtRev\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Calculate a productivity index ** #\n",
    "dt['PI'] = dt['TotalCost']/dt['TotalRev']\n",
    "# with these cleanings the base reduced to about 200.000 rows, then I convert the base to pandas dataframe #\n",
    "dt2 = dt.compute()\n",
    "del dt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Third cleaning data ** #\n",
    "dt2 = dt2[(dt2['PI'].notnull()) & ((dt2['PI']>=0) & (dt2['PI']<1.5))]\n",
    "dt2 = dt2.assign(PI_cat = lambda dataframe:datframe['PI'].map(lambda PI:'Adequado' if PI < 0.56 else 'Inadequado')) # equal mutate(dplyr)\n",
    "# Filter just cost and total revenue variable #\n",
    "cols = [c for c in dt2.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,28]]]\n",
    "db = dt2.loc[:,cols]\n",
    "del dt2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Forth cleaning data ** #\n",
    "shop.columns = shop.columns.str.replace(\" \",\"\")\n",
    "shop = shop.iloc[:, [0, 6, 12]]\n",
    "shop = shop.rename(columns = {'CodSho':'shop'})\n",
    "shop = shop.astype({'shop':int})\n",
    "\n",
    "db[\"shop\"] = db[\"shopDate\"].str.split(\"_\", 1).str.get(0) #generate the variabel 'shop' from 'shopDate'\n",
    "db = db.astype({'shop':int})\n",
    "db = pd.merge(db, shop, on = 'shop', how = 'left')\n",
    "\n",
    "def regionBR(x):\n",
    "    if x in ['AC', 'AP', 'AM', 'PA', 'RO', 'RR', 'TO']:\n",
    "        value = 'Norte'\n",
    "    elif x in ['CE', 'AL', 'BA', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE']:\n",
    "        value = 'Nordeste'\n",
    "    elif x in ['GO', 'MT', 'MS', 'DF']:\n",
    "        value = 'Centro-Oeste'\n",
    "    elif x in ['ES', 'MG', 'RJ', 'SP']:\n",
    "        value = 'Sudeste'\n",
    "    elif x in ['PR', 'SC', 'RS']:\n",
    "        value = 'Sul'\n",
    "    else:\n",
    "        value 'Other'\n",
    "    return value\n",
    "\n",
    "db = db.assign(region = db['UF'].apply(regionBR)) #equal mutate(dplyr)\n",
    "gc.collect()\n",
    "\n",
    "# The dataframe is now clean and I can normalize the data, create new variables...., to application machine leraning algoritm #\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
